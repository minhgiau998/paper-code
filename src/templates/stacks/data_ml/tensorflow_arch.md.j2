# TensorFlow / Keras Project Architecture

## ğŸ—ï¸ High-Level Overview

This project is built using **TensorFlow 2.x** and **Keras 3**.
It follows a modular architecture designed for scalability and seamless deployment to **TF Serving** or **TFLite**.

## ğŸ“‚ Directory Structure

```text
root/
â”œâ”€â”€ configs/             # Hyperparameter configurations (YAML)
â”œâ”€â”€ data/                # Data directory
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ tfrecords/       # Serialized high-performance data
â”‚   â””â”€â”€ external/
â”œâ”€â”€ notebooks/           # Prototyping (Exploration only)
â”œâ”€â”€ saved_models/        # Exported models (.keras, SavedModel)
â”œâ”€â”€ logs/                # TensorBoard logs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/            # ETL Pipelines
â”‚   â”‚   â”œâ”€â”€ pipeline.py  # tf.data.Dataset builders
â”‚   â”‚   â””â”€â”€ preprocessing.py # Keras Preprocessing Layers
â”‚   â”œâ”€â”€ models/          # Model Definitions
â”‚   â”‚   â”œâ”€â”€ layers/      # Custom Keras Layers
â”‚   â”‚   â””â”€â”€ networks.py  # Functional API definitions
â”‚   â”œâ”€â”€ training/        # Training Loops / Callbacks
â”‚   â”‚   â”œâ”€â”€ callbacks.py # Custom Checkpoints/Logging
â”‚   â”‚   â””â”€â”€ losses.py    # Custom Loss Functions
â”‚   â””â”€â”€ serving/         # Export logic for production
â”œâ”€â”€ train.py             # Training Entry Point
â””â”€â”€ requirements.txt
```

## ğŸ§© Key Architectural Patterns

### 1. Data Pipeline (`tf.data`)
We strictly use **`tf.data`** for the input pipeline.
- **Extract:** Read from disk (Images, Text, TFRecords).
- **Transform:** Apply augmentations using `tf.image` or Keras Preprocessing Layers mapped over the dataset.
- **Load:** Prefetch to GPU memory.

### 2. Model Definition (Keras 3)
We prefer the **Functional API** for model definition.
- **Functional API:** Best for static graphs, ease of visualization, and serialization.
- **Subclassing:** Use only when dynamic control flow (loops/conditionals inside `call`) is strictly necessary.

### 3. Preprocessing inside Model
- Include preprocessing logic (Resizing, Normalization, Tokenization) **inside the model graph** using Keras Preprocessing Layers.
- **Benefit:** The exported model accepts raw data (strings/bytes), eliminating training-serving skew.

### 4. XLA Compilation
- We leverage XLA (Accelerated Linear Algebra) to optimize graph execution.
- Models are compiled with `jit_compile=True` where supported.

## ğŸ“Š Deployment Strategy
- **Format:** Models are saved in the modern Keras v3 format (`model.keras`).
- **Serving:** For high-throughput production, models are exported to the TensorFlow **SavedModel** format for Docker/TF Serving.